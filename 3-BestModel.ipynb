{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model - Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel, SelectPercentile, f_classif\n",
    "\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output variables\n",
    "outVar = 'Class'\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_baseline(cls, X_tr, y_tr, X_ts, y_ts, seed=42, classes=['0','1']):\n",
    "    ACC = 0\n",
    "    AUROC = 0\n",
    "    precision = 0 \n",
    "    recall = 0\n",
    "    f1score = 0\n",
    "    \n",
    "    cls_name = type(cls).__name__\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cls.fit(X_tr, y_tr)\n",
    "    print('>', cls_name, \"training: %0.2f mins \" % ((time.time() - start_time)/60))\n",
    "    \n",
    "    # predictions\n",
    "    y_pred  = cls.predict(X_ts)\n",
    "    y_probs = cls.predict_proba(X_ts)[:, 1]\n",
    "    cls_rep = classification_report(y_ts, y_pred, target_names=classes,\n",
    "                                    output_dict=True, digits=3)\n",
    "    print(cls_rep)\n",
    "    \n",
    "    ACC       = accuracy_score(y_ts, y_pred)\n",
    "    AUROC     = roc_auc_score(y_ts, y_probs)\n",
    "    precision = cls_rep['weighted avg']['precision']\n",
    "    recall    = cls_rep['weighted avg']['recall']\n",
    "    f1score   = cls_rep['weighted avg']['f1-score']  \n",
    "    \n",
    "    return cls, ACC, AUROC, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tr and ts datasets\n",
    "df_tr_std = feather.read_dataframe(r'datasets\\ds.Class.std.tr.feather')\n",
    "df_ts_std = feather.read_dataframe(r'datasets\\ds.Class.std.ts.feather')\n",
    "\n",
    "# get data for tr and ts\n",
    "X_tr_std = df_tr_std.drop(outVar, axis=1).values\n",
    "y_tr_std = df_tr_std[outVar].values\n",
    "X_ts_std = df_ts_std.drop(outVar, axis=1).values\n",
    "y_ts_std = df_ts_std[outVar].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifiers for baseline\n",
    "classifiers = [\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.5)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for ML baseline\n",
    "df_ML = pd.DataFrame(columns=['Method', 'n_estimators', 'max_samples', 'ACC','AUROC' ,'precision' ,'recall' ,'f1-score' ])\n",
    "df_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit each classifier\n",
    "for cls in classifiers:\n",
    "    print(\"\\n***\", cls)\n",
    "    cls_fit, ACC,AUROC,precision,recall,f1score=ML_baseline(cls, X_tr_std, y_tr_std, X_ts_std, y_ts_std)\n",
    "    df_ML = df_ML.append({'Method': str(type(cls).__name__),\n",
    "                          'n_estimators': cls_fit.n_estimators,\n",
    "                          'max_samples': cls_fit.max_samples,\n",
    "                          'ACC': float(ACC),\n",
    "                          'AUROC': float(AUROC),\n",
    "                          'precision': float(precision),\n",
    "                          'recall': float(recall),\n",
    "                          'f1-score': float(f1score)}, ignore_index=True)\n",
    "\n",
    "df_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs.best_estimator_\n",
    "feature_importances = np.mean([\n",
    "    tree.feature_importances_ for tree in cls_fit.estimators_\n",
    "], axis=0)\n",
    "print(len(feature_importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df = pd.DataFrame(columns = ['Feature','Importance'])\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df['Feature']=list(df_tr_std.columns)[:-1]\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df['Importance']=feature_importances\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df.to_csv(r'results\\bestModel_featImps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "joblib.dump(cls_fit, r'results\\best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_ord = feat_imp_df.sort_values('Importance', ascending=False)\n",
    "feat_imp_df_ord.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_ord.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_ord.to_csv(r'results\\bestModel_featImps_ordered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df.sort_values('Importance', ascending=False).head(52).sort_values('Importance', ascending=True).plot(kind='barh',x='Feature',y='Importance', figsize=(10,15))\n",
    "plt.show() # half from 104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_ord.tail(52).plot(kind='barh',x='Feature',y='Importance', figsize=(10,15))\n",
    "plt.show() # half from 104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df.sort_values('Importance', ascending=True).plot(kind='barh',x='Feature',y='Importance', figsize=(10,30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try remove some features to improve the model?Â¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_ord.tail(20).sort_values('Importance', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to remove\n",
    "feats2Rem = list(feat_imp_df_ord.tail(20).sort_values('Importance', ascending=True)['Feature'])\n",
    "print(feats2Rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "BestClassifier = BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for ML baseline\n",
    "df_FeatsImpRem = pd.DataFrame(columns=['Removed Feature', 'ACC','AUROC' ,'precision' ,'recall' ,'f1-score' ])\n",
    "df_FeatsImpRem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** Feature elimination by importance\")\n",
    "print(\"\\n***\", BestClassifier)\n",
    "\n",
    "# read tr and ts datasets\n",
    "df_tr_std_orig = feather.read_dataframe(r'datasets\\ds.Class.std.tr.feather')\n",
    "df_ts_std_orig = feather.read_dataframe(r'datasets\\ds.Class.std.ts.feather')\n",
    "    \n",
    "# fit each classifier\n",
    "for nFeats in range(1,len(feats2Rem)+1):\n",
    "    # remove a number of features\n",
    "    remFeatures = feats2Rem[:nFeats] # removed features\n",
    "    \n",
    "    print(\"-> Removed features:\", remFeatures)\n",
    "    df_tr_std = df_tr_std_orig.drop(remFeatures, axis=1)\n",
    "    df_ts_std = df_ts_std_orig.drop(remFeatures, axis=1)\n",
    "\n",
    "    # get data for tr and ts\n",
    "    X_tr_std = df_tr_std.drop(outVar, axis=1).values\n",
    "    y_tr_std = df_tr_std[outVar].values\n",
    "    X_ts_std = df_ts_std.drop(outVar, axis=1).values\n",
    "    y_ts_std = df_ts_std[outVar].values\n",
    "    \n",
    "    cls_fit, ACC,AUROC,precision,recall,f1score=ML_baseline(cls, X_tr_std, y_tr_std, X_ts_std, y_ts_std)\n",
    "    df_FeatsImpRem = df_FeatsImpRem.append({'Removed Feature': remFeatures,\n",
    "                                            'ACC': float(ACC),\n",
    "                                            'AUROC': float(AUROC),\n",
    "                                            'precision': float(precision),\n",
    "                                            'recall': float(recall),\n",
    "                                            'f1-score': float(f1score)}, ignore_index=True)\n",
    "\n",
    "df_FeatsImpRem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FeatsImpRem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FeatsImpRem.to_csv(r'results\\bestModel_20featsRem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra features to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Importance between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_ord['Importance'] = scaler.fit_transform(feat_imp_df_ord['Importance'].values.reshape(-1, 1))\n",
    "feat_imp_df_ord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_ord.to_csv(r'results\\bestModel_bestModel_featImps_ordered_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2Refeats2Rem_less10percm_less10perc = feat_imp_df_ord[feat_imp_df_ord['Importance']<0.1]\n",
    "len(feats2Refeats2Rem_less10percm_less10perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2Refeats2Rem_less10percm_less10perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2Refeats2Rem_less10percm_less10perc = feats2Refeats2Rem_less10percm_less10perc.sort_values('Importance', ascending=True)\n",
    "feats2Refeats2Rem_less10percm_less10perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to remove with importance less than 10%\n",
    "feats2Rem2 = list(feats2Refeats2Rem_less10percm_less10perc['Feature'])\n",
    "print(len(feats2Rem2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate more features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** Feature elimination by importance\")\n",
    "print(\"\\n***\", BestClassifier)\n",
    "\n",
    "# read tr and ts datasets\n",
    "df_tr_std_orig = feather.read_dataframe(r'datasets\\ds.Class.std.tr.feather')\n",
    "df_ts_std_orig = feather.read_dataframe(r'datasets\\ds.Class.std.ts.feather')\n",
    "    \n",
    "# fit each classifier\n",
    "for nFeats in range(35,len(feats2Rem2)+1):\n",
    "    # remove a number of features\n",
    "    remFeatures = feats2Rem2[:nFeats] # removed features\n",
    "    \n",
    "    print(\"-> Removed features:\", remFeatures)\n",
    "    df_tr_std = df_tr_std_orig.drop(remFeatures, axis=1)\n",
    "    df_ts_std = df_ts_std_orig.drop(remFeatures, axis=1)\n",
    "\n",
    "    # get data for tr and ts\n",
    "    X_tr_std = df_tr_std.drop(outVar, axis=1).values\n",
    "    y_tr_std = df_tr_std[outVar].values\n",
    "    X_ts_std = df_ts_std.drop(outVar, axis=1).values\n",
    "    y_ts_std = df_ts_std[outVar].values\n",
    "    \n",
    "    cls_fit, ACC,AUROC,precision,recall,f1score=ML_baseline(cls, X_tr_std, y_tr_std, X_ts_std, y_ts_std)\n",
    "    df_FeatsImpRem = df_FeatsImpRem.append({'Removed Feature': remFeatures,\n",
    "                                            'ACC': float(ACC),\n",
    "                                            'AUROC': float(AUROC),\n",
    "                                            'precision': float(precision),\n",
    "                                            'recall': float(recall),\n",
    "                                            'f1-score': float(f1score)}, ignore_index=True)\n",
    "\n",
    "df_FeatsImpRem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FeatsImpRem.to_csv(r'results\\bestModel_72featsRem_less10perc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BoxPlot = df_FeatsImpRem[['ACC', 'AUROC', 'precision', 'recall', 'f1-score']]\n",
    "df_BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_BoxPlot['ACC'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_BoxPlot['AUROC'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FeatsImpRem.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_tr_std.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df_tr_std.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose 64 feature to eliminate (point 63): 'np_DNMUnp(c5)', 'np_DPDIcoat(c3)', 'np_DPDIcoat(c0)', 'np_DPDIcoat(c1)', 'np_DPDIcoat(c2)', 'np_DALOGPcoat(c0)', 'np_DALOGPcoat(c2)', 'np_DHycoat(c0)', 'np_DALOGPcoat(c1)', 'np_DHycoat(c3)', 'np_DUicoat(c0)', 'np_DHycoat(c2)', 'np_DAMRcoat(c3)', 'np_DHycoat(c1)', 'np_DALOGPcoat(c3)', 'np_DEnpu(c5)', 'np_DUicoat(c3)', 'np_DUccoat(c3)', 'np_DEnpu(c3)', 'np_DUccoat(c1)', 'np_DUicoat(c1)', 'np_DEnpu(c0)', 'np_DSAdoncoat(c3)', 'np_DVxcoat(c3)', 'np_DSAtotcoat(c3)', 'np_DALOGP2coat(c3)', 'np_DTPSA(Tot)coat(c3)', 'np_DSAacccoat(c3)', 'np_DTPSA(NO)coat(c3)', 'np_DVvdwMGcoat(c3)', 'np_DUccoat(c2)', 'np_DTPSA(NO)coat(c0)', 'np_DUicoat(c2)', 'np_DSAtotcoat(c1)', 'np_DVvdwZAZcoat(c3)', 'np_DTPSA(Tot)coat(c2)', 'np_DTPSA(Tot)coat(c0)', 'np_DNMUnp(c3)', 'np_DVvdwMGcoat(c0)', 'np_DSAdoncoat(c1)', 'np_DALOGP2coat(c0)', 'np_DUccoat(c0)', 'np_DAMRcoat(c2)', 'np_DVvdwZAZcoat(c1)', 'np_DALOGP2coat(c2)', 'np_DTPSA(NO)coat(c2)', 'np_DSAacccoat(c2)', 'np_DVxcoat(c2)', 'np_DVxcoat(c0)', 'np_DEnpu(c2)', 'np_DTPSA(NO)coat(c1)', 'np_DVxcoat(c1)', 'np_DSAacccoat(c1)', 'np_DALOGP2coat(c1)', 'np_DTPSA(Tot)coat(c1)', 'np_DVvdwZAZcoat(c2)', 'np_DSAdoncoat(c0)', 'np_DVvdwMGcoat(c1)', 'np_DEnpu(c1)', 'np_DVvdwMGcoat(c2)', 'np_DVvdwZAZcoat(c0)', 'np_DAMRcoat(c1)', 'np_DSAdoncoat(c2)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_std = feather.read_dataframe(r'datasets\\ds.Class.std.tr.feather')\n",
    "df_ts_std = feather.read_dataframe(r'datasets\\ds.Class.std.ts.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tr_std.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((df_FeatsImpRem[63:64])['Removed Feature'])\n",
    "Removed = df_FeatsImpRem.iloc[63, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-> Removed features:\", Removed)\n",
    "df_tr_std = df_tr_std.drop(Removed, axis=1)\n",
    "df_ts_std = df_ts_std.drop(Removed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final descriptors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_tr_std.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tr_std.columns)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final dataset splits with 41 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather.write_dataframe(df_tr_std, r'datasets\\ds.Final41feats.std.tr.feather')\n",
    "feather.write_dataframe(df_ts_std, r'datasets\\ds.Final41feats.std.ts.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_std.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tr_std.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_std.shape[0] + df_ts_std.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_tr_std.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@muntisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
