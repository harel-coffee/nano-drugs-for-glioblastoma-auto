{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel, SelectPercentile, f_classif\n",
    "\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output variables\n",
    "outVar = 'Class'\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs.best_estimator_\n",
    "feature_importances = np.mean([\n",
    "    tree.feature_importances_ for tree in gs.best_estimator_.estimators_\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_baseline(cls, X_tr, y_tr, X_ts, y_ts, seed=42, classes=['0','1']):\n",
    "    ACC = 0\n",
    "    AUROC = 0\n",
    "    precision = 0 \n",
    "    recall = 0\n",
    "    f1score = 0\n",
    "    \n",
    "    cls_name = type(cls).__name__\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cls.fit(X_tr, y_tr)\n",
    "    print('>', cls_name, \"training: %0.2f mins \" % ((time.time() - start_time)/60))\n",
    "    \n",
    "    # predictions\n",
    "    y_pred  = cls.predict(X_ts)\n",
    "    y_probs = cls.predict_proba(X_ts)[:, 1]\n",
    "    cls_rep = classification_report(y_ts, y_pred, target_names=classes,\n",
    "                                    output_dict=True, digits=3)\n",
    "    print(cls_rep)\n",
    "    \n",
    "    ACC       = accuracy_score(y_ts, y_pred)\n",
    "    AUROC     = roc_auc_score(y_ts, y_probs)\n",
    "    precision = cls_rep['weighted avg']['precision']\n",
    "    recall    = cls_rep['weighted avg']['recall']\n",
    "    f1score   = cls_rep['weighted avg']['f1-score']  \n",
    "    \n",
    "    return cls, ACC, AUROC, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tr and ts datasets\n",
    "df_tr_std = feather.read_dataframe(r'datasets\\ds.Class.std.tr.feather')\n",
    "df_ts_std = feather.read_dataframe(r'datasets\\ds.Class.std.ts.feather')\n",
    "\n",
    "# get data for tr and ts\n",
    "X_tr_std = df_tr_std.drop(outVar, axis=1).values\n",
    "y_tr_std = df_tr_std[outVar].values\n",
    "X_ts_std = df_ts_std.drop(outVar, axis=1).values\n",
    "y_ts_std = df_ts_std[outVar].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifiers for baseline\n",
    "classifiers = [\n",
    "               BaggingClassifier(random_state=seed, n_estimators= 5, max_samples=0.5),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=10, max_samples=0.5),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.5),\n",
    "               BaggingClassifier(random_state=seed, n_estimators= 5, max_samples=0.6),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=10, max_samples=0.6),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.6),\n",
    "               BaggingClassifier(random_state=seed, n_estimators= 5, max_samples=1.0),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=10, max_samples=1.0),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=1.0)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifiers for baseline\n",
    "classifiers = [\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.1),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.2),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.3),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.4),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.5),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.6),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.7),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.8),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=0.9),\n",
    "               BaggingClassifier(random_state=seed, n_estimators=20, max_samples=1.0)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for ML baseline\n",
    "df_ML = pd.DataFrame(columns=['Method', 'n_estimators', 'max_samples', 'ACC','AUROC' ,'precision' ,'recall' ,'f1-score' ])\n",
    "df_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit each classifier\n",
    "for cls in classifiers:\n",
    "    print(\"\\n***\", cls)\n",
    "    cls_fit, ACC,AUROC,precision,recall,f1score=ML_baseline(cls, X_tr_std, y_tr_std, X_ts_std, y_ts_std)\n",
    "    df_ML = df_ML.append({'Method': str(type(cls).__name__),\n",
    "                          'n_estimators': cls_fit.n_estimators,\n",
    "                          'max_samples': cls_fit.max_samples,\n",
    "                          'ACC': float(ACC),\n",
    "                          'AUROC': float(AUROC),\n",
    "                          'precision': float(precision),\n",
    "                          'recall': float(recall),\n",
    "                          'f1-score': float(f1score)}, ignore_index=True)\n",
    "\n",
    "df_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML.to_csv(r'results\\gs_Bagging_max_samples.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@muntisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
